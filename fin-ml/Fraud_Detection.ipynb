{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.8.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (4.0.1)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow) (59.5.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost\n",
    "\n",
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv, set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Libraries for Deep Learning Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#Libraries for Saving the Model\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"https://raw.githubusercontent.com/tatsath/fin-ml/master/Chapter%206%20-%20Sup.%20Learning%20-%20Classification%20models/CaseStudy1%20-%20Fraud%20Detection/creditcard_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>67374</td>\n",
       "      <td>-0.228866</td>\n",
       "      <td>0.086431</td>\n",
       "      <td>0.791165</td>\n",
       "      <td>-1.451021</td>\n",
       "      <td>1.141154</td>\n",
       "      <td>0.070110</td>\n",
       "      <td>0.442420</td>\n",
       "      <td>-0.128557</td>\n",
       "      <td>0.305720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162295</td>\n",
       "      <td>0.732803</td>\n",
       "      <td>-0.380588</td>\n",
       "      <td>-1.086826</td>\n",
       "      <td>0.376692</td>\n",
       "      <td>-0.481770</td>\n",
       "      <td>-0.077937</td>\n",
       "      <td>-0.220115</td>\n",
       "      <td>9.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>67374</td>\n",
       "      <td>-1.336121</td>\n",
       "      <td>1.671947</td>\n",
       "      <td>0.994155</td>\n",
       "      <td>0.420318</td>\n",
       "      <td>-0.440923</td>\n",
       "      <td>-0.008386</td>\n",
       "      <td>-0.893860</td>\n",
       "      <td>-2.051884</td>\n",
       "      <td>-1.091297</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.135695</td>\n",
       "      <td>0.509302</td>\n",
       "      <td>0.074188</td>\n",
       "      <td>0.266186</td>\n",
       "      <td>-0.117614</td>\n",
       "      <td>-0.515392</td>\n",
       "      <td>-0.049653</td>\n",
       "      <td>0.085873</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>67374</td>\n",
       "      <td>0.662465</td>\n",
       "      <td>-1.336560</td>\n",
       "      <td>0.791566</td>\n",
       "      <td>0.425701</td>\n",
       "      <td>-1.391976</td>\n",
       "      <td>0.145471</td>\n",
       "      <td>-0.476652</td>\n",
       "      <td>0.203164</td>\n",
       "      <td>1.379204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063744</td>\n",
       "      <td>-0.548785</td>\n",
       "      <td>-0.103769</td>\n",
       "      <td>0.136687</td>\n",
       "      <td>-0.078936</td>\n",
       "      <td>0.948579</td>\n",
       "      <td>-0.075607</td>\n",
       "      <td>0.053555</td>\n",
       "      <td>269.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>67374</td>\n",
       "      <td>-4.930001</td>\n",
       "      <td>-1.090715</td>\n",
       "      <td>0.298037</td>\n",
       "      <td>1.890524</td>\n",
       "      <td>-1.058087</td>\n",
       "      <td>-0.329315</td>\n",
       "      <td>-1.498278</td>\n",
       "      <td>1.750301</td>\n",
       "      <td>-0.325311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051768</td>\n",
       "      <td>0.166222</td>\n",
       "      <td>-0.585006</td>\n",
       "      <td>0.219239</td>\n",
       "      <td>0.181934</td>\n",
       "      <td>-0.253197</td>\n",
       "      <td>0.113801</td>\n",
       "      <td>-1.043315</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>67374</td>\n",
       "      <td>0.982019</td>\n",
       "      <td>-0.161026</td>\n",
       "      <td>0.534280</td>\n",
       "      <td>0.714558</td>\n",
       "      <td>0.108865</td>\n",
       "      <td>1.154723</td>\n",
       "      <td>-0.298831</td>\n",
       "      <td>0.417264</td>\n",
       "      <td>0.368293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074225</td>\n",
       "      <td>0.088060</td>\n",
       "      <td>0.158234</td>\n",
       "      <td>-0.580906</td>\n",
       "      <td>0.100103</td>\n",
       "      <td>0.373722</td>\n",
       "      <td>0.047812</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>27.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99999 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0          0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1          0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2          1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3          1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4          2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "99994  67374 -0.228866  0.086431  0.791165 -1.451021  1.141154  0.070110   \n",
       "99995  67374 -1.336121  1.671947  0.994155  0.420318 -0.440923 -0.008386   \n",
       "99996  67374  0.662465 -1.336560  0.791566  0.425701 -1.391976  0.145471   \n",
       "99997  67374 -4.930001 -1.090715  0.298037  1.890524 -1.058087 -0.329315   \n",
       "99998  67374  0.982019 -0.161026  0.534280  0.714558  0.108865  1.154723   \n",
       "\n",
       "             V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0      0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1     -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2      0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3      0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4      0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "99994  0.442420 -0.128557  0.305720  ...  0.162295  0.732803 -0.380588   \n",
       "99995 -0.893860 -2.051884 -1.091297  ... -1.135695  0.509302  0.074188   \n",
       "99996 -0.476652  0.203164  1.379204  ... -0.063744 -0.548785 -0.103769   \n",
       "99997 -1.498278  1.750301 -0.325311  ...  0.051768  0.166222 -0.585006   \n",
       "99998 -0.298831  0.417264  0.368293  ... -0.074225  0.088060  0.158234   \n",
       "\n",
       "            V24       V25       V26       V27       V28  Amount  Class  \n",
       "0      0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1     -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2     -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3     -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4      0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "...         ...       ...       ...       ...       ...     ...    ...  \n",
       "99994 -1.086826  0.376692 -0.481770 -0.077937 -0.220115    9.06      0  \n",
       "99995  0.266186 -0.117614 -0.515392 -0.049653  0.085873    2.50      0  \n",
       "99996  0.136687 -0.078936  0.948579 -0.075607  0.053555  269.83      0  \n",
       "99997  0.219239  0.181934 -0.253197  0.113801 -1.043315   45.00      0  \n",
       "99998 -0.580906  0.100103  0.373722  0.047812  0.005941   27.88      0  \n",
       "\n",
       "[99999 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99999, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.360</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>2.536</td>\n",
       "      <td>1.378</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.192</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358</td>\n",
       "      <td>-1.340</td>\n",
       "      <td>1.773</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.909</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>1.793</td>\n",
       "      <td>-0.863</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>1.247</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-1.176</td>\n",
       "      <td>0.647</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.061</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158</td>\n",
       "      <td>0.878</td>\n",
       "      <td>1.549</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.593</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>0.818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.798</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.215</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time     V1     V2     V3     V4     V5     V6     V7     V8     V9  ...  \\\n",
       "0     0 -1.360 -0.073  2.536  1.378 -0.338  0.462  0.240  0.099  0.364  ...   \n",
       "1     0  1.192  0.266  0.166  0.448  0.060 -0.082 -0.079  0.085 -0.255  ...   \n",
       "2     1 -1.358 -1.340  1.773  0.380 -0.503  1.800  0.791  0.248 -1.515  ...   \n",
       "3     1 -0.966 -0.185  1.793 -0.863 -0.010  1.247  0.238  0.377 -1.387  ...   \n",
       "4     2 -1.158  0.878  1.549  0.403 -0.407  0.096  0.593 -0.271  0.818  ...   \n",
       "\n",
       "     V21    V22    V23    V24    V25    V26    V27    V28  Amount  Class  \n",
       "0 -0.018  0.278 -0.110  0.067  0.129 -0.189  0.134 -0.021  149.62      0  \n",
       "1 -0.226 -0.639  0.101 -0.340  0.167  0.126 -0.009  0.015    2.69      0  \n",
       "2  0.248  0.772  0.909 -0.689 -0.328 -0.139 -0.055 -0.060  378.66      0  \n",
       "3 -0.108  0.005 -0.190 -1.176  0.647 -0.222  0.063  0.061  123.50      0  \n",
       "4 -0.009  0.798 -0.137  0.141 -0.206  0.502  0.219  0.215   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('precision', 3)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not_Fraud    99776\n",
       "Fraud          223\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Class\"].value_counts().rename(index={0:\"Not_Fraud\",1:\"Fraud\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f759cf758d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bf1ec90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bf57f90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bf127d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bec8ad0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757be7edd0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f757be43c10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bdfd410>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bdfde90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f759d010910>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f759cfa7ed0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bd96f90>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f757bd597d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bd0cfd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bccd810>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bc80f90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bc43850>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bc02bd0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f757bbb7890>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bb77c10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757bb2f8d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757baeac50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757baa6910>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757ba62c90>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f757ba99950>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757ba57cd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757ba10990>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757b9cfd10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757b9869d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757b943d50>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f757b89da10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757b85bd90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757b810a50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757b7d2dd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757b787a90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f757b748e10>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 36 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.hist(xlabelsize=1, ylabelsize=1, figsize=(12,12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Specs      Score\n",
      "17   V17  20657.815\n",
      "14   V14  16227.609\n",
      "3     V3  10383.969\n",
      "12   V12   9644.180\n",
      "10   V10   7909.706\n",
      "16   V16   6829.653\n",
      "7     V7   6157.564\n",
      "11   V11   3567.597\n",
      "4     V4   2840.800\n",
      "18   V18   2632.037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "bestfeatures = SelectKBest(k=10)\n",
    "X = dataset.iloc[:, :-1]\n",
    "Y = dataset.iloc[:, -1]\n",
    "fit = bestfeatures.fit(X,Y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Train-test split and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train,X_validation,Y_train,Y_validation = train_test_split(X,Y,test_size=validation_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Checking Models and Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 3\n",
    "scoring = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append((\"XGB\",XGBClassifier()))\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:16:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:16:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:17:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB: 0.999475 (0.000153)\n",
      "LR: 0.998437 (0.000071)\n",
      "LDA: 0.999075 (0.000127)\n",
      "KNN: 0.997762 (0.000289)\n",
      "CART: 0.999050 (0.000124)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = pyplot.figure()\n",
    "fig.suptitle(\"Algorithm comparison\")\n",
    "ax= fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "fig.set_size_inches(8,4)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99915\n",
      "[[19948     8]\n",
      " [    9    35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19956\n",
      "           1       0.81      0.80      0.80        44\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.91      0.90      0.90     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Model  Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:58:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:58:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:59:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB: 0.814127 (0.078712)\n",
      "LR: 0.530387 (0.046477)\n",
      "LDA: 0.734513 (0.112089)\n",
      "KNN: 0.000000 (0.000000)\n",
      "CART: 0.778793 (0.077158)\n"
     ]
    }
   ],
   "source": [
    "scoring = \"recall\"\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:03:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
       "              num_parallel_tree=1, objective='binary:logistic',\n",
       "              predictor='auto', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=True, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99915\n",
      "[[19948     8]\n",
      " [    9    35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19956\n",
      "           1       0.81      0.80      0.80        44\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.91      0.90      0.90     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Model Tuning for balancing the sample by Random Under Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X_train,Y_train],axis=1)\n",
    "# amount of fraud classes 175 rows.\n",
    "fraud_df = df.loc[df[\"Class\"]==1]\n",
    "non_fraud_df = df.loc[df[\"Class\"]==0][:179]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_distributed_df = pd.concat([fraud_df,non_fraud_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    179\n",
       "0    179\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = normal_distributed_df.sample(frac=1,random_state=42) # frac daj mi uzorak koji nije isti\n",
    "Y_train_new = df_new[\"Class\"]\n",
    "X_train_new = df_new.loc[:,dataset.columns !=\"Class\"]\n",
    "\n",
    "Y_train_new.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot check the algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append((\"XGB\",XGBClassifier()));\n",
    "# Boosting methods\n",
    "models.append(('AB', AdaBoostClassifier()))\n",
    "models.append(('GBM', GradientBoostingClassifier()))\n",
    "# Bagging methods\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('ET', ExtraTreesClassifier()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring='recall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.921963 (0.027341)\n",
      "LDA: 0.828684 (0.060608)\n",
      "KNN: 0.586809 (0.009574)\n",
      "CART: 0.921196 (0.023005)\n",
      "NB: 0.859937 (0.029591)\n",
      "SVM: 0.500144 (0.093179)\n",
      "[09:31:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:31:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB: 0.927428 (0.020149)\n",
      "AB: 0.921963 (0.027341)\n",
      "GBM: 0.938357 (0.009011)\n",
      "RF: 0.916115 (0.013657)\n",
      "ET: 0.910651 (0.020111)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train_new, Y_train_new, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
